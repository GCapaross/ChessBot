{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1200a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "# Load the move dictionary created during the data-processing\n",
    "MOVE_DICTIONARY = pickle.load(open(\"../dataset/processed/test_elite/move_dictionary.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66156df7",
   "metadata": {},
   "source": [
    "# Initialize Dataset and Dataload\n",
    "## Dataset\n",
    "Our dataset consists of around 10M moves, played by humans with Lichess ELO of at least 2100, to ensure quality moves, pre-processed in file `data_processing.ipynb`\n",
    "Our dataset is written in csv files, with just two columns `bitmaps` that represent the game state and `move played` that represents the game played by a human in that game state. \n",
    "\n",
    "As our dataset contains a very large number of examples we load it in batches of `NUM_EXAMPLES_TO_LOAD_PER_FETCH`, normally 640k examples at a time.\n",
    "This is imperative as fetching 1.2M examples will use around 5gb ram, and, since the training was made in a GPU with 6GB of VRAM, we couldn't load the entire dataset at once.\n",
    "\n",
    "This loaded batch is shuffled to prevent any inherent order or pattern in the data from affecting the training, especially sinced our data consists of moves of games that are read in order.\n",
    "\n",
    "## Dataloader\n",
    "Dataloader serves the purpose of fetching the data from our dataset and dividing the examples in batches of `TRAINING_BATCH_SIZE` elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e442ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ChessDataset import ChessEvalDataset\n",
    "\n",
    "DATASET_PATH = '../dataset/processed/test_elite/results_black.csv'\n",
    "## !IMPORTANT: This dictates how much ram will be used, and how much data will be loaded\n",
    "# 1_280_000 loads around 5gb, dont push this too high as it will crash if ram deplects\n",
    "# NUM_EXAMPLES_TO_LOAD_PER_FETCH = 1_280_000 \n",
    "NUM_EXAMPLES_TO_LOAD_PER_FETCH = 640_000\n",
    "TRAINING_BATCH_SIZE = 64\n",
    "\n",
    "HEADERS = (\"bitmaps\", \"movePlayed\")\n",
    "dataset = ChessEvalDataset(\n",
    "    file = DATASET_PATH, \n",
    "    validation_size = 25_000,\n",
    "    load_batch_size = NUM_EXAMPLES_TO_LOAD_PER_FETCH, \n",
    "    headers = HEADERS\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=TRAINING_BATCH_SIZE, shuffle=False) # Shuffle is made in the dataset manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967d507",
   "metadata": {},
   "source": [
    "# Model\n",
    "We use a model, saved in the file `model.py`present in the folder `./model/models/architecture_2Conv/model.py` (this allowed us to have a versioning system of our models) \n",
    "\n",
    "The final model consists of two Convolutional layers and two fully connected layers, that receive a 8x8x12 tensor, which represent the game state (8x8 squares, 6 white pieces and 6 black pieces)\n",
    "\n",
    "And has 1800 outputs, each represent a played move (moves played in our dataset)\n",
    "We didn't used all possible moves (64x63 moves) because since we didn't have all the possible moves represented in our dataset our model wasn't converging to acceptable values (40% validation accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf001f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import gc\n",
    "# from models.architecture_batchnorm_2Conv.model import CompleteChessBotNetwork\n",
    "from models.architecture_2Conv_classes.model import old_ChessModel\n",
    "model = old_ChessModel(len(MOVE_DICTIONARY)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f021dc7",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "Our training loop, written in pseudocode:\n",
    "```\n",
    "For each epoch:\n",
    "    For batch in dataloader.get_next_batch():\n",
    "        bitmaps, expected_moves = batch\n",
    "        predictions = model.predict(bitmaps)\n",
    "\n",
    "        loss = CrossEntropyLoss(predictions, expected_moves)\n",
    "        loss.backpropagation()\n",
    "\n",
    "    validation_dataset = get_validation_dataset()\n",
    "    loss, accuracy = evaluate_accuracy(validation_dataset)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        save_model(model)\n",
    "```\n",
    "We also save the weights of our model every 5 epochs.\n",
    "\n",
    "## Optimizer and Scheduler\n",
    "We use, as an optimizer, Adam (Adaptive Moment Estimation) optimizer, which adjust learning rates during training, as it works well with large datasets and complex models because it uses memory efficiently and adapts the learning rate for each parameter automatically.\n",
    "\n",
    "## Loss Function\n",
    "As a classification problem, we use Cross Entropy Loss to calculate the loss of each batch\n",
    "\n",
    "## Model Accuracy Evaluation\n",
    "To evaluate our model, we extract, in the beginning, 50k examples from the dataset that are never used in the training phase, which allows us to see how well our model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7916a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Accuracy: 25.00%: 100%|██████████| 39063/39063 [02:54<00:00, 223.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - 1.4295 | Training Accuracy: 55.61%| Time: 175.75114679336548\n",
      "Validation set - accuracy: 32.63% | loss: 3.2437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39063 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m avg_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     16\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboard_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m        \u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboard_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_eval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_eval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Move data to GPU\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/src/model/ChessDataset.py:81\u001b[39m, in \u001b[36mChessEvalDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     78\u001b[39m batch_id = idx // \u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Get the batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m features, targets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Get the item from the batch\u001b[39;00m\n\u001b[32m     84\u001b[39m idx_in_batch = \u001b[38;5;28mself\u001b[39m.idxs[idx % \u001b[38;5;28mself\u001b[39m.batch_size]  \u001b[38;5;66;03m# Get the next index from the shuffled list sorted(range(0, len(batch))) [ ]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/src/model/ChessDataset.py:66\u001b[39m, in \u001b[36mChessEvalDataset._get_batch\u001b[39m\u001b[34m(self, batch_id)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Process features and target\u001b[39;00m\n\u001b[32m     65\u001b[39m features = batch_dataset.select(\u001b[38;5;28mself\u001b[39m.feature_col)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m features = torch.tensor(np.array(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_array_bitmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbitmaps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbitmaps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbitmaps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m), dtype=torch.float32)\n\u001b[32m     68\u001b[39m played_moves = batch_dataset.select(\u001b[38;5;28mself\u001b[39m.target_col).to_numpy()\n\u001b[32m     69\u001b[39m targets = torch.tensor(played_moves, dtype=torch.long)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/src/model/ChessDataset.py:66\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Process features and target\u001b[39;00m\n\u001b[32m     65\u001b[39m features = batch_dataset.select(\u001b[38;5;28mself\u001b[39m.feature_col)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m features = torch.tensor(np.array([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_array_bitmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbitmaps\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m bitmaps \u001b[38;5;129;01min\u001b[39;00m features[\u001b[33m\"\u001b[39m\u001b[33mbitmaps\u001b[39m\u001b[33m\"\u001b[39m]]), dtype=torch.float32)\n\u001b[32m     68\u001b[39m played_moves = batch_dataset.select(\u001b[38;5;28mself\u001b[39m.target_col).to_numpy()\n\u001b[32m     69\u001b[39m targets = torch.tensor(played_moves, dtype=torch.long)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A/LEI/3_Ano/2_Semestre/TAA/ChessBot/src/model/ChessDataset.py:99\u001b[39m, in \u001b[36mChessEvalDataset.convert_to_array_bitmap\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\"\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03mConverts board into array\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     96\u001b[39m \u001b[33;03m:return: np.ndarray[shape(13, 8, 8), dtype=np.float32]]:\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     98\u001b[39m NUM_CHANNELS = \u001b[32m12\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m boards = np.array(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m, dtype=np.uint64) \u001b[38;5;66;03m# shape = (13,)\u001b[39;00m\n\u001b[32m    100\u001b[39m array = np.empty((NUM_CHANNELS, \u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m), dtype=np.uint8)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Set pieces boards\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.raw_decode(s, idx=\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.end())\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "OUTPUT_PATH = './models/architecture_2Conv_classes/blackOnly_64batch'\n",
    "\n",
    "# Continue with pretrained weights\n",
    "model.load_state_dict(torch.load(\"./models/architecture_2Conv_classes/blackOnly_64batch/epoch-165.pth\"))\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Using device: \", device)\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    avg_loss = 0.0\n",
    "    correct = 0\n",
    "    for board_tensor, target_eval in (pbar := tqdm.tqdm(dataloader)):        \n",
    "        board_tensor, target_eval = board_tensor.to(device), target_eval.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(board_tensor)\n",
    "\n",
    "        # Compute loss with valid move vlaidaiton\n",
    "        loss = loss_fn(pred, target_eval.squeeze(1))\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        batch_correct = (pred.argmax(dim=1) == target_eval[:, 0]).sum().item()\n",
    "        correct += batch_correct\n",
    "        pbar.set_description(f\"Batch Accuracy: {batch_correct*100 / (TRAINING_BATCH_SIZE):.2f}%\")\n",
    "    # scheduler.step()\n",
    "    \n",
    "    # Validation set\n",
    "    model.eval()\n",
    "    validation_features, validation_targets = dataset.get_validation_set()\n",
    "    validation_features = validation_features.to(device)\n",
    "    validation_targets = validation_targets.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(validation_features)\n",
    "        validation_set_loss = loss_fn(pred, validation_targets.squeeze(1))\n",
    "        validation_set_correct = (pred.argmax(dim=1) == validation_targets[:, 0]).sum().item()\n",
    "        validation_set_accuracy = 100 * validation_set_correct / len(validation_targets)\n",
    "        pred = pred.cpu()\n",
    "        validation_features = validation_features.cpu()\n",
    "        validation_targets = validation_targets.cpu()\n",
    "\n",
    "    accuracy = 100 * correct / (len(dataloader) * TRAINING_BATCH_SIZE)\n",
    "    tf = time.time()\n",
    "    print(f\"Epoch {epoch} - {avg_loss / len(dataloader):.4f} | Training Accuracy: {accuracy:.2f}%| Time: {tf-t0}\")\n",
    "    print(f\"Validation set - accuracy: {validation_set_accuracy:.2f}% | loss: {validation_set_loss:.4f}\\n\")\n",
    "\n",
    "    # Free GPU memory\n",
    "    del validation_features, validation_targets, validation_set_loss, validation_set_accuracy\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"{OUTPUT_PATH}/epoch-{epoch}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

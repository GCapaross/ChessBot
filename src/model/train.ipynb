{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1200a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import chess\n",
    "from time import time\n",
    "import tqdm\n",
    "\n",
    "HEADERS = (\"bitmaps\", \"movePlayed\", \"validMoves\")\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class PositionEvaluatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(13, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.tanh(self.fc2(x))  # Output between -1 and 1\n",
    "    \n",
    "\n",
    "class ChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13,64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "\n",
    "class CompleteChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13,64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64 * 63) # (Choose 2 squares from the board where the order matters) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.conv1(x))\n",
    "        x = self.sigmoid(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "## Idea:\n",
    "##   One model that answers \"best piece to move in this position\"\n",
    "##   Then another model that answers \"best square to move piece X to\"\n",
    "\n",
    "# Add normalization after conv\n",
    "# Switch from relu to sigmoid or smth\n",
    "# Add more preprocessing by making the tensors there and avoid pre processing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def board_to_tensor(board):\n",
    "    tensor = np.zeros((12, 8, 8), dtype=np.uint8)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_idx[piece.symbol()]\n",
    "            row = 7 - square // 8\n",
    "            col = square % 8\n",
    "            tensor[idx, row, col] = 1\n",
    "    return tensor\n",
    "\n",
    "def convert_to_array(row: str):\n",
    "    \"\"\"\"\n",
    "    Converts board into array\n",
    "\n",
    "    :param str row: Board with side to play;\n",
    "                        This must represent a np.ndarray[np.int64, shape=(13)] \n",
    "    :return: np.ndarray[shape(13, 8, 8), dtype=np.float32]]:\n",
    "    \"\"\"\n",
    "    boards = np.array(json.loads(row), dtype=np.uint64) # shape = (13,)\n",
    "    array = np.empty((13, 8, 8), dtype=np.uint8)\n",
    "\n",
    "    # Set pieces boards\n",
    "    board_int8_view = boards.view(dtype=np.uint8).reshape((13, 8)) # shape = (13, 8)\n",
    "    board_as_int = np.unpackbits(board_int8_view, axis=1).reshape((13, 8, 8))\n",
    "    array[:] = board_as_int\n",
    "\n",
    "    # Set side to play board\n",
    "    array[12] = np.ones(shape = (1, 8, 8)) if boards[12] == 1 else np.zeros(shape=(1,8,8))\n",
    "    return array\n",
    "\n",
    "\n",
    "letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "numbers = list(range(1, 10)) # [1..9]\n",
    "MOVE_DICTIONARY = {}\n",
    "cumulative = 0\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        for k in range(8):\n",
    "            for w in range (8):\n",
    "                if (i == k and j == w):\n",
    "                    cumulative += 1\n",
    "                    continue\n",
    "                from_square = f\"{letters[i]}{numbers[j]}\"\n",
    "                to_square = f\"{letters[k]}{numbers[w]}\"\n",
    "                MOVE_DICTIONARY[f\"{from_square}{to_square}\"] = (i * 8**3) + (j * 8**2) + (k * 8) + w - cumulative\n",
    "REVERSE_MOVE_DICTIONARY = {\n",
    "    value: key for key,value in MOVE_DICTIONARY.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e442ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import polars as pl\n",
    "\n",
    "class ChessEvalDataset(Dataset):\n",
    "# class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, file: str, model: Literal[\"pieces\", \"moves\"] = \"pieces\", load_batch_size = 6_400):\n",
    "        self.model = model\n",
    "        self.lazy_dataset = pl.scan_csv(file, has_header=False, new_columns=HEADERS)\n",
    "        self.batch_size = load_batch_size\n",
    "        self.feature_col = \"bitmaps\"\n",
    "        self.target_col = \"movePlayed\"\n",
    "        self.total_rows = self.lazy_dataset.select(pl.len()).collect().item()\n",
    "\n",
    "        self.cached_batches: dict[int, tuple] = {}\n",
    "        self.cached_batch_id: int | None = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_rows\n",
    "    \n",
    "    def _get_batch(self, batch_id):\n",
    "        \"\"\"Load a specific batch of data, wrapped with lru_cache for memory management\"\"\"\n",
    "        # Calculate batch range\n",
    "        if batch_id == self.cached_batch_id:\n",
    "            return self.cached_batches[batch_id]\n",
    "        self.cached_batches.pop(self.cached_batch_id, None) # Delete old batch\n",
    "        \n",
    "        # Calculate batch range\n",
    "        start_idx = batch_id * self.batch_size\n",
    "        end_idx = min((batch_id + 1) * self.batch_size, self.total_rows)\n",
    "        \n",
    "        # Fetch only this batch of data using offset and limit\n",
    "        batch_dataset = (self.lazy_dataset\n",
    "                    .slice(start_idx, end_idx - start_idx)\n",
    "                    .collect())\n",
    "        \n",
    "        # Process features and target\n",
    "        features = batch_dataset.select(self.feature_col)\n",
    "        features = torch.tensor(np.array([convert_to_array(bitmaps) for bitmaps in features[\"bitmaps\"]]), dtype=torch.float32)\n",
    "        \n",
    "        played_moves = batch_dataset.select(self.target_col).to_numpy()\n",
    "        # valid_moves = batch_dataset.select(\"validMoves\").to_numpy()\n",
    "        valid_moves = np.zeros(shape=np.shape(played_moves))\n",
    "\n",
    "        targets = np.array([played_moves, valid_moves], dtype=np.float32)\n",
    "        targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "        self.cached_batch_id = batch_id\n",
    "        self.cached_batches[self.cached_batch_id] = (features, targets)\n",
    "        \n",
    "        return self.cached_batches[batch_id]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which batch this index belongs to\n",
    "        batch_id = idx // self.batch_size\n",
    "        # Get the batch\n",
    "        features, targets = self._get_batch(batch_id)\n",
    "        # Get the item from the batch\n",
    "        idx_in_batch = idx % self.batch_size\n",
    "\n",
    "        return features[idx_in_batch], targets[:, idx_in_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a4a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_MOVE_LOSS = -0.5\n",
    "INVALID_MOVE_LOSS = +10\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def bitmaps_to_board(bitmaps):\n",
    "    board = chess.Board(fen = \"8/8/8/8/8/8/8/8 w KQkq - 0 1\")\n",
    "    for piece_name, piece_idx in piece_to_idx.items():\n",
    "        for row in range(8):\n",
    "            for col in range(8):\n",
    "                if bitmaps[piece_idx][row][col] == 1:\n",
    "                    piece = chess.Piece(piece_idx, chess.WHITE) if piece_idx < 6 else chess.Piece(piece_idx - 6, chess.BLACK)\n",
    "                    board.set_piece_at(row * 8 + col, piece)\n",
    "    return board\n",
    "\n",
    "# LOSS FUNCTION\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "def loss_fn(outputs: torch.Tensor, targets): # targets tensor with twp elements: [targets, possible_moves]\n",
    "    loss = cross_entropy_loss(outputs, targets[0])\n",
    "\n",
    "    played_move = [output.argmax().item() for output in outputs]\n",
    "    # game_board = [bitmaps_to_board(bitmaps) for bitmaps in batch_bitmaps]\n",
    "    penalization = VALID_MOVE_LOSS\n",
    "    # for move in played_move:\n",
    "\n",
    "    return torch.add(loss, penalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:51<00:00, 302.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - 3.5338 | Time: 171.02689218521118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 302.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - 2.5336 | Time: 170.96192598342896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - 2.2681 | Time: 169.36138129234314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - 2.1291 | Time: 169.44144797325134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - 2.0450 | Time: 169.45404505729675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - 1.9900 | Time: 168.66061568260193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - 1.9508 | Time: 168.92704105377197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - 1.9209 | Time: 169.66611075401306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - 1.8971 | Time: 168.71227622032166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - 1.8778 | Time: 169.83908343315125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:52<00:00, 300.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - 1.8618 | Time: 172.45528602600098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 304.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - 1.8483 | Time: 170.18055033683777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:51<00:00, 302.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - 1.8364 | Time: 171.15522742271423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - 1.8263 | Time: 169.73297119140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 306.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - 1.8172 | Time: 169.0251874923706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:53<00:00, 298.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - 1.8092 | Time: 173.5646812915802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:45<00:00, 312.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - 1.8018 | Time: 165.93786597251892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - 1.7951 | Time: 169.9509949684143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 304.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - 1.7891 | Time: 170.1909146308899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - 1.7836 | Time: 169.7792990207672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 19997/51773 [01:06<01:38, 321.77it/s]"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '../dataset/processed/results_with_valid_moves_no_skip.csv'\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "TRAINING_MODE = \"pieces\" # \"pieces\" or \"moves\"\n",
    "MODEL_WEIGHTS_OUTPUT_PATH = \"./models/CompleteModel_noskip_FINISHED.pth\"\n",
    "\n",
    "## !IMPORTANT: This dictates how much ram will be used, and how much data will be loaded\n",
    "# 1_280_000 loads around 5gb, dont push this too high as it will crash if ram deplects\n",
    "NUM_EXAMPLES_TO_LOAD_PER_FETCH = 1_280_000 \n",
    "\n",
    "test = ChessEvalDataset(file = DATASET_PATH, model=TRAINING_MODE, load_batch_size = NUM_EXAMPLES_TO_LOAD_PER_FETCH)\n",
    "loader = DataLoader(test, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CompleteChessBotNetwork().to(device)\n",
    "\n",
    "# Continue with pretrained weights\n",
    "# model.load_state_dict(torch.load('./models/CompleteModel_Epoch-80.pth'))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Using device: \", device)\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    t0 = time()\n",
    "    avg_loss = 0.0\n",
    "    i = 1\n",
    "    for board_tensor, target_eval in tqdm.tqdm(loader):\n",
    "        valid_moves = target_eval[:, 1, :]\n",
    "        target_eval = target_eval[:, 0, :] \n",
    "        \n",
    "        board_tensor_gpu, target_eval_gpu = board_tensor.to(device), target_eval.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(board_tensor_gpu)\n",
    "\n",
    "        # Compute loss with valid move vlaidaiton\n",
    "        # loss = loss_fn(board_tensor, pred, target_eval_gpu.squeeze(1))\n",
    "        loss = loss_fn(pred, target_eval_gpu.squeeze(1))\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "        i+=1\n",
    "\n",
    "    tf = time()\n",
    "    print(f\"Epoch {epoch} - {avg_loss / len(loader):.4f} | Time: {tf-t0}\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"./models/CompleteModel_noskip_epoch-{epoch}.pth\")\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

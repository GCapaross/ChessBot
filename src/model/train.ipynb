{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1200a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import chess\n",
    "from time import time\n",
    "import tqdm\n",
    "\n",
    "HEADERS = (\"bitmaps\", \"movePlayed\", \"validMoves\")\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class PositionEvaluatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(13, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.tanh(self.fc2(x))  # Output between -1 and 1\n",
    "    \n",
    "\n",
    "class ChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13,64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "\n",
    "class CompleteChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13,64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64 * 63) # (Choose 2 squares from the board where the order matters) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.conv1(x))\n",
    "        x = self.sigmoid(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "## Idea:\n",
    "##   One model that answers \"best piece to move in this position\"\n",
    "##   Then another model that answers \"best square to move piece X to\"\n",
    "\n",
    "# Add normalization after conv\n",
    "# Switch from relu to sigmoid or smth\n",
    "# Add more preprocessing by making the tensors there and avoid pre processing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def board_to_tensor(board):\n",
    "    tensor = np.zeros((12, 8, 8), dtype=np.uint8)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_idx[piece.symbol()]\n",
    "            row = 7 - square // 8\n",
    "            col = square % 8\n",
    "            tensor[idx, row, col] = 1\n",
    "    return tensor\n",
    "\n",
    "def convert_to_array(row: str):\n",
    "    \"\"\"\"\n",
    "    Converts board into array\n",
    "\n",
    "    :param str row: Board with side to play;\n",
    "                        This must represent a np.ndarray[np.int64, shape=(13)] \n",
    "    :return: np.ndarray[shape(13, 8, 8), dtype=np.float32]]:\n",
    "    \"\"\"\n",
    "    boards = np.array(json.loads(row), dtype=np.uint64) # shape = (13,)\n",
    "    array = np.empty((13, 8, 8), dtype=np.uint8)\n",
    "\n",
    "    # Set pieces boards\n",
    "    board_int8_view = boards.view(dtype=np.uint8).reshape((13, 8)) # shape = (13, 8)\n",
    "    board_as_int = np.unpackbits(board_int8_view, axis=1).reshape((13, 8, 8))\n",
    "    array[:] = board_as_int\n",
    "\n",
    "    # Set side to play board\n",
    "    array[12] = np.ones(shape = (1, 8, 8)) if boards[12] == 1 else np.zeros(shape=(1,8,8))\n",
    "    return array\n",
    "\n",
    "\n",
    "letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "numbers = list(range(1, 10)) # [1..9]\n",
    "MOVE_DICTIONARY = {}\n",
    "cumulative = 0\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        for k in range(8):\n",
    "            for w in range (8):\n",
    "                if (i == k and j == w):\n",
    "                    cumulative += 1\n",
    "                    continue\n",
    "                from_square = f\"{letters[i]}{numbers[j]}\"\n",
    "                to_square = f\"{letters[k]}{numbers[w]}\"\n",
    "                MOVE_DICTIONARY[f\"{from_square}{to_square}\"] = (i * 8**3) + (j * 8**2) + (k * 8) + w - cumulative\n",
    "REVERSE_MOVE_DICTIONARY = {\n",
    "    value: key for key,value in MOVE_DICTIONARY.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e442ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import polars as pl\n",
    "\n",
    "class ChessEvalDataset(Dataset):\n",
    "# class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, file: str, model: Literal[\"pieces\", \"moves\"] = \"pieces\", load_batch_size = 6_400):\n",
    "        self.model = model\n",
    "        self.lazy_dataset = pl.scan_csv(file, has_header=False, new_columns=HEADERS)\n",
    "        self.batch_size = load_batch_size\n",
    "        self.feature_col = \"bitmaps\"\n",
    "        self.target_col = \"movePlayed\"\n",
    "        self.total_rows = self.lazy_dataset.select(pl.len()).collect().item()\n",
    "\n",
    "        self.cached_batches: dict[int, tuple] = {}\n",
    "        self.cached_batch_id: int | None = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_rows\n",
    "    \n",
    "    def _get_batch(self, batch_id):\n",
    "        \"\"\"Load a specific batch of data, wrapped with lru_cache for memory management\"\"\"\n",
    "        # Calculate batch range\n",
    "        if batch_id == self.cached_batch_id:\n",
    "            return self.cached_batches[batch_id]\n",
    "        self.cached_batches.pop(self.cached_batch_id, None) # Delete old batch\n",
    "        \n",
    "        # Calculate batch range\n",
    "        start_idx = batch_id * self.batch_size\n",
    "        end_idx = min((batch_id + 1) * self.batch_size, self.total_rows)\n",
    "        \n",
    "        # Fetch only this batch of data using offset and limit\n",
    "        batch_dataset = (self.lazy_dataset\n",
    "                    .slice(start_idx, end_idx - start_idx)\n",
    "                    .collect())\n",
    "        \n",
    "        # Process features and target\n",
    "        features = batch_dataset.select(self.feature_col)\n",
    "        features = torch.tensor(np.array([convert_to_array(bitmaps) for bitmaps in features[\"bitmaps\"]]), dtype=torch.float32)\n",
    "        \n",
    "        played_moves = batch_dataset.select(self.target_col).to_numpy()\n",
    "        # valid_moves = batch_dataset.select(\"validMoves\").to_numpy()\n",
    "        valid_moves = np.zeros(shape=np.shape(played_moves))\n",
    "\n",
    "        targets = np.array([played_moves, valid_moves], dtype=np.float32)\n",
    "        targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "        self.cached_batch_id = batch_id\n",
    "        self.cached_batches[self.cached_batch_id] = (features, targets)\n",
    "        \n",
    "        return self.cached_batches[batch_id]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which batch this index belongs to\n",
    "        batch_id = idx // self.batch_size\n",
    "        # Get the batch\n",
    "        features, targets = self._get_batch(batch_id)\n",
    "        # Get the item from the batch\n",
    "        idx_in_batch = idx % self.batch_size\n",
    "\n",
    "        return features[idx_in_batch], targets[:, idx_in_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_MOVE_LOSS = -0.5\n",
    "INVALID_MOVE_LOSS = +10\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def bitmaps_to_board(bitmaps):\n",
    "    board = chess.Board(fen = \"8/8/8/8/8/8/8/8 w KQkq - 0 1\")\n",
    "    for piece_name, piece_idx in piece_to_idx.items():\n",
    "        for row in range(8):\n",
    "            for col in range(8):\n",
    "                if bitmaps[piece_idx][row][col] == 1:\n",
    "                    piece = chess.Piece(piece_idx, chess.WHITE) if piece_idx < 6 else chess.Piece(piece_idx - 6, chess.BLACK)\n",
    "                    board.set_piece_at(row * 8 + col, piece)\n",
    "    return board\n",
    "\n",
    "# LOSS FUNCTION\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "def loss_fn(outputs: torch.Tensor, targets, valid_moves): # targets tensor with twp elements: [targets, possible_moves]\n",
    "    loss = cross_entropy_loss(outputs, targets)\n",
    "\n",
    "    played_move = [output.argmax().item() for output in outputs]\n",
    "    penalization = VALID_MOVE_LOSS\n",
    "    for move, valid_moves in zip(played_move, valid_moves):\n",
    "        num_idx = move // 64\n",
    "        bit_idx = move % 64\n",
    "        num = valid_moves[num_idx]\n",
    "        if (num >> bit_idx) & 1 == 0:\n",
    "            penalization += INVALID_MOVE_LOSS\n",
    "        else:\n",
    "            penalization += VALID_MOVE_LOSS\n",
    "    return torch.add(loss, penalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:51<00:00, 302.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - 3.5338 | Time: 171.02689218521118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 302.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - 2.5336 | Time: 170.96192598342896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - 2.2681 | Time: 169.36138129234314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - 2.1291 | Time: 169.44144797325134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - 2.0450 | Time: 169.45404505729675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - 1.9900 | Time: 168.66061568260193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - 1.9508 | Time: 168.92704105377197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - 1.9209 | Time: 169.66611075401306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - 1.8971 | Time: 168.71227622032166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - 1.8778 | Time: 169.83908343315125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:52<00:00, 300.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - 1.8618 | Time: 172.45528602600098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 304.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - 1.8483 | Time: 170.18055033683777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:51<00:00, 302.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - 1.8364 | Time: 171.15522742271423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 305.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - 1.8263 | Time: 169.73297119140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 306.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - 1.8172 | Time: 169.0251874923706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:53<00:00, 298.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - 1.8092 | Time: 173.5646812915802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:45<00:00, 312.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - 1.8018 | Time: 165.93786597251892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - 1.7951 | Time: 169.9509949684143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:50<00:00, 304.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - 1.7891 | Time: 170.1909146308899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:49<00:00, 304.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - 1.7836 | Time: 169.7792990207672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:54<00:00, 297.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - 1.7786 | Time: 174.10879158973694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [02:48<00:00, 306.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - 1.7739 | Time: 168.64929223060608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [04:43<00:00, 182.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - 1.7698 | Time: 283.80107975006104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [04:56<00:00, 174.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - 1.7657 | Time: 296.8620948791504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [04:51<00:00, 177.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - 1.7620 | Time: 291.61624121665955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51773/51773 [03:21<00:00, 256.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - 1.7585 | Time: 201.78068947792053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 46618/51773 [02:31<00:16, 307.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Compute loss with valid move vlaidaiton\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# loss = loss_fn(board_tensor, pred, target_eval_gpu.squeeze(1))\u001b[39;00m\n\u001b[32m     41\u001b[39m loss = loss_fn(pred, target_eval_gpu.squeeze(\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[32m     45\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A1/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A1/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/jgaspar/7CCE3FA7CE3F589A1/LEI/3_Ano/2_Semestre/TAA/ChessBot/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '../dataset/processed/results_with_valid_moves_no_skip.csv'\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "TRAINING_MODE = \"pieces\" # \"pieces\" or \"moves\"\n",
    "MODEL_WEIGHTS_OUTPUT_PATH = \"./models/CompleteModel_noskip_FINISHED.pth\"\n",
    "\n",
    "## !IMPORTANT: This dictates how much ram will be used, and how much data will be loaded\n",
    "# 1_280_000 loads around 5gb, dont push this too high as it will crash if ram deplects\n",
    "NUM_EXAMPLES_TO_LOAD_PER_FETCH = 1_280_000 \n",
    "\n",
    "test = ChessEvalDataset(file = DATASET_PATH, model=TRAINING_MODE, load_batch_size = NUM_EXAMPLES_TO_LOAD_PER_FETCH)\n",
    "loader = DataLoader(test, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CompleteChessBotNetwork().to(device)\n",
    "\n",
    "# Continue with pretrained weights\n",
    "# model.load_state_dict(torch.load('./models/CompleteModel_Epoch-80.pth'))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Using device: \", device)\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    t0 = time()\n",
    "    avg_loss = 0.0\n",
    "    i = 1\n",
    "    for board_tensor, target_eval in tqdm.tqdm(loader):\n",
    "        valid_moves = target_eval[:, 1, :]\n",
    "        target_eval = target_eval[:, 0, :] \n",
    "        \n",
    "        board_tensor_gpu, target_eval_gpu = board_tensor.to(device), target_eval.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(board_tensor_gpu)\n",
    "\n",
    "        # Compute loss with valid move vlaidaiton\n",
    "        # loss = loss_fn(board_tensor, pred, target_eval_gpu.squeeze(1))\n",
    "        loss = loss_fn(pred, target_eval_gpu.squeeze(1), valid_moves)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "        i+=1\n",
    "\n",
    "    tf = time()\n",
    "    print(f\"Epoch {epoch} - {avg_loss / len(loader):.4f} | Time: {tf-t0}\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"./models/CompleteModel_noskip_epoch-{epoch}.pth\")\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1200a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import chess\n",
    "from time import time\n",
    "import tqdm\n",
    "\n",
    "HEADERS = (\"bitmaps\", \"movePlayed\", \"validMoves\")\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5bc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class PositionEvaluatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(13, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.tanh(self.fc2(x))  # Output between -1 and 1\n",
    "    \n",
    "\n",
    "class ChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13,64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "\n",
    "class _CompleteChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256) # 8 * 8 (num of squares) * 128 (num of channels)\n",
    "        self.fc2 = nn.Linear(256, 64 * 63) # (Choose 2 squares from the board where the order matters)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "\n",
    "class CompleteChessBotNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 13 channels: 12 pieces + side to play (tensor[true's|false's])\n",
    "\n",
    "        self.inputLayer = nn.Conv2d(13, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        self.convLayers = nn.Sequential(\n",
    "            self.inputLayer,\n",
    "            self.batchnorm0,\n",
    "            nn.ReLU(),\n",
    "            self.conv1,\n",
    "            self.batchnorm1,\n",
    "            nn.ReLU(),\n",
    "            self.conv2,\n",
    "            self.batchnorm2,\n",
    "            nn.ReLU(),\n",
    "            self.conv3,\n",
    "            self.batchnorm3,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 256) # 8 * 8 (num of squares) * 128 (num of channels)\n",
    "        self.fc2 = nn.Linear(256, 64 * 63) # (Choose 2 squares from the board where the order matters)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.kaiming_uniform_(self.inputLayer.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_uniform_(self.conv3.weight, nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convLayers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output raw logits\n",
    "        return x\n",
    "## Idea:\n",
    "##   One model that answers \"best piece to move in this position\"\n",
    "##   Then another model that answers \"best square to move piece X to\"\n",
    "\n",
    "# Add normalization after conv\n",
    "# Switch from relu to sigmoid or smth\n",
    "# Add more preprocessing by making the tensors there and avoid pre processing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0338429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def board_to_tensor(board):\n",
    "    tensor = np.zeros((12, 8, 8), dtype=np.uint8)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = piece_to_idx[piece.symbol()]\n",
    "            row = 7 - square // 8\n",
    "            col = square % 8\n",
    "            tensor[idx, row, col] = 1\n",
    "    return tensor\n",
    "\n",
    "def convert_to_array_bitmap(row: str):\n",
    "    \"\"\"\"\n",
    "    Converts board into array\n",
    "\n",
    "    :param str row: Board with side to play;\n",
    "                        This must represent a np.ndarray[np.int64, shape=(13)] \n",
    "    :return: np.ndarray[shape(13, 8, 8), dtype=np.float32]]:\n",
    "    \"\"\"\n",
    "    boards = np.array(json.loads(row), dtype=np.uint64) # shape = (13,)\n",
    "    array = np.empty((13, 8, 8), dtype=np.uint8)\n",
    "\n",
    "    # Set pieces boards\n",
    "    board_int8_view = boards.view(dtype=np.uint8).reshape((13, 8)) # shape = (13, 8)\n",
    "    board_as_int = np.unpackbits(board_int8_view, axis=1).reshape((13, 8, 8))\n",
    "    array[:] = board_as_int\n",
    "\n",
    "    # Set side to play board\n",
    "    array[12] = np.ones(shape = (1, 8, 8)) if boards[12] == 1 else np.zeros(shape=(1,8,8))\n",
    "    return array\n",
    "\n",
    "\n",
    "letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "numbers = list(range(1, 10)) # [1..9]\n",
    "MOVE_DICTIONARY = {}\n",
    "cumulative = 0\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        for k in range(8):\n",
    "            for w in range (8):\n",
    "                if (i == k and j == w):\n",
    "                    cumulative += 1\n",
    "                    continue\n",
    "                from_square = f\"{letters[i]}{numbers[j]}\"\n",
    "                to_square = f\"{letters[k]}{numbers[w]}\"\n",
    "                MOVE_DICTIONARY[f\"{from_square}{to_square}\"] = (i * 8**3) + (j * 8**2) + (k * 8) + w - cumulative\n",
    "REVERSE_MOVE_DICTIONARY = {\n",
    "    value: key for key,value in MOVE_DICTIONARY.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e442ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "class ChessEvalDataset(Dataset):\n",
    "# class ChessEvalDataset(IterableDataset):\n",
    "    def __init__(self, file: str, model: Literal[\"pieces\", \"moves\"] = \"pieces\", load_batch_size = 6_400):\n",
    "        self.model = model\n",
    "        self.lazy_dataset = pl.scan_csv(file, has_header=False, new_columns=HEADERS)\n",
    "        self.batch_size = load_batch_size\n",
    "        self.feature_col = \"bitmaps\"\n",
    "        self.target_col = \"movePlayed\"\n",
    "        self.total_rows = self.lazy_dataset.select(pl.len()).collect().item()\n",
    "\n",
    "        self.cached_batches: dict[int, tuple] = {}\n",
    "        self.cached_batch_id: int | None = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_rows\n",
    "    \n",
    "    def _get_batch(self, batch_id):\n",
    "        \"\"\"Load a specific batch of data, wrapped with lru_cache for memory management\"\"\"\n",
    "        # Calculate batch range\n",
    "        if batch_id == self.cached_batch_id:\n",
    "            return self.cached_batches[batch_id]\n",
    "        \n",
    "\n",
    "        self.cached_batches.pop(self.cached_batch_id, None) # Delete old batch\n",
    "        \n",
    "        # Calculate batch range\n",
    "        start_idx = batch_id * self.batch_size\n",
    "        end_idx = min((batch_id + 1) * self.batch_size, self.total_rows)\n",
    "        self.idxs = [i for i in range(end_idx - start_idx)]\n",
    "        random.shuffle(self.idxs) # Shuffle the indices for the batch\n",
    "        \n",
    "        # Fetch only this batch of data using offset and limit\n",
    "        batch_dataset = (self.lazy_dataset\n",
    "                    .slice(start_idx, end_idx - start_idx)\n",
    "                    .collect())\n",
    "        \n",
    "        # Process features and target\n",
    "        features = batch_dataset.select(self.feature_col)\n",
    "        features = torch.tensor(np.array([convert_to_array_bitmap(bitmaps) for bitmaps in features[\"bitmaps\"]]), dtype=torch.float32)\n",
    "        \n",
    "        played_moves = batch_dataset.select(self.target_col).to_numpy()\n",
    "        targets = torch.tensor(played_moves, dtype=torch.long)\n",
    "\n",
    "        valid_moves = batch_dataset.select(\"validMoves\")\n",
    "        valid_moves = torch.tensor(np.array([json.loads(row) for row in valid_moves[\"validMoves\"]], dtype=np.uint64))\n",
    "        # valid_moves = np.zeros(shape=np.shape(played_moves))\n",
    "\n",
    "\n",
    "        self.cached_batch_id = batch_id\n",
    "        self.cached_batches[self.cached_batch_id] = (features, targets, valid_moves)\n",
    "        \n",
    "        return self.cached_batches[batch_id]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate which batch this index belongs to\n",
    "        batch_id = idx // self.batch_size\n",
    "        # Get the batch\n",
    "        features, targets, valid_moves = self._get_batch(batch_id)\n",
    "\n",
    "        # Get the item from the batch\n",
    "        idx_in_batch = self.idxs[idx % self.batch_size]  # Get the next index from the shuffled list\n",
    "\n",
    "        return features[idx_in_batch], targets[idx_in_batch], valid_moves[idx_in_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a4a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_MOVE_LOSS = -0.1/1024\n",
    "INVALID_MOVE_LOSS = +10/1024\n",
    "\n",
    "piece_to_idx = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "def bitmaps_to_board(bitmaps):\n",
    "    board = chess.Board(fen = \"8/8/8/8/8/8/8/8 w KQkq - 0 1\")\n",
    "    for piece_name, piece_idx in piece_to_idx.items():\n",
    "        for row in range(8):\n",
    "            for col in range(8):\n",
    "                if bitmaps[piece_idx][row][col] == 1:\n",
    "                    piece = chess.Piece(piece_idx, chess.WHITE) if piece_idx < 6 else chess.Piece(piece_idx - 6, chess.BLACK)\n",
    "                    board.set_piece_at(row * 8 + col, piece)\n",
    "    return board\n",
    "\n",
    "# LOSS FUNCTION\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "def loss_fn(outputs: torch.Tensor, targets, valid_moves): # targets tensor with twp elements: [targets, possible_moves]\n",
    "    loss = cross_entropy_loss(outputs, targets)\n",
    "\n",
    "    played_move = [output.argmax().item() for output in outputs]\n",
    "    penalization = 0\n",
    "    invalid_played = False\n",
    "    for move, valid_moves in zip(played_move, valid_moves):\n",
    "        num_idx = move // 64\n",
    "        bit_idx = move % 64\n",
    "        num = valid_moves[num_idx]\n",
    "\n",
    "        shift_tensor = torch.tensor(1 << bit_idx, dtype=num.dtype) \n",
    "\n",
    "        if num & shift_tensor != 0:\n",
    "            # invalid_played = True\n",
    "            penalization += INVALID_MOVE_LOSS\n",
    "        else:\n",
    "            penalization += VALID_MOVE_LOSS\n",
    "            \n",
    "    # if invalid_played:\n",
    "        # penalization += INVALID_MOVE_LOSS\n",
    "    return torch.add(loss, penalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Accuracy: 58.30%:   5%|â–         | 625/13759 [00:53<14:59, 14.60it/s] "
     ]
    }
   ],
   "source": [
    "# DATASET_PATH = '../dataset/processed/results_ELO_1500.csv'\n",
    "DATASET_PATH = '../dataset/processed/results_ELO_1500_250k.csv'\n",
    "NUM_EPOCHS = 400\n",
    "\n",
    "TRAINING_MODE = \"pieces\" # \"pieces\" or \"moves\"\n",
    "MODEL_WEIGHTS_OUTPUT_PATH = \"./models/architecture_6Conv/retrain_epoch160_250k/FINISHED.pth\"\n",
    "\n",
    "## !IMPORTANT: This dictates how much ram will be used, and how much data will be loaded\n",
    "# 1_280_000 loads around 5gb, dont push this too high as it will crash if ram deplects\n",
    "# NUM_EXAMPLES_TO_LOAD_PER_FETCH = 1_280_000 \n",
    "NUM_EXAMPLES_TO_LOAD_PER_FETCH = 640_000\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "test = ChessEvalDataset(file = DATASET_PATH, model=TRAINING_MODE, load_batch_size = NUM_EXAMPLES_TO_LOAD_PER_FETCH)\n",
    "loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CompleteChessBotNetwork().to(device)\n",
    "\n",
    "# Continue with pretrained weights\n",
    "model.load_state_dict(torch.load('./models/architecture_6Conv/train_50k/CompleteModel_new_architecture_skipmoves_epoch-160.pth'))\n",
    "# model.load_state_dict(torch.load('./models/CompleteModel_noskip_version2_epoch-170.pth'))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(\"Using device: \", device)\n",
    "for epoch in range(0, NUM_EPOCHS+1):\n",
    "    model.train()\n",
    "    t0 = time()\n",
    "    avg_loss = 0.0\n",
    "    i = 1\n",
    "    correct = 0\n",
    "    for board_tensor, target_eval, valid_moves in (pbar := tqdm.tqdm(loader)):        \n",
    "        board_tensor_gpu, target_eval_gpu = board_tensor.to(device), target_eval.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(board_tensor_gpu)\n",
    "\n",
    "        # Compute loss with valid move vlaidaiton\n",
    "        # loss = loss_fn(board_tensor, pred, target_eval_gpu.squeeze(1))\n",
    "        loss = loss_fn(pred, target_eval_gpu.squeeze(1), valid_moves)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "        i+=1\n",
    "\n",
    "        batch_correct = (pred.argmax(dim=1) == target_eval_gpu[:, 0]).sum().item()\n",
    "        correct += batch_correct\n",
    "        pbar.set_description(f\"Batch Accuracy: {batch_correct*100 / (BATCH_SIZE):.2f}%\")\n",
    "\n",
    "    accuracy = 100 * correct / (len(loader) * BATCH_SIZE)\n",
    "    tf = time()\n",
    "    print(f\"Epoch {epoch} - {avg_loss / len(loader):.4f} | Accuracy: {accuracy:.2f}% | Time: {tf-t0}\", end=\"\\r\")\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"./models/architecture_6Conv/retrain_epoch160_250k/epoch-{epoch}.pth\")\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_OUTPUT_PATH)\n",
    "\n",
    "# filtra 1100 - 14000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
